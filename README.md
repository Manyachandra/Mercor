# Mercor Challenge: Referral Network

*Author: Manya Chandra, Python 3.11, Submission for Mercor Coding Challenge, 2025*

## ğŸ“Œ Challenge Overview
This repository contains a **complete, fully specâ€‘compliant** implementation of the *Mercor Challenge: Referral Network*.  
It delivers all five parts defined in the official problem statement â€” from referral graph management to referral bonus optimization â€” **in the same order as the specification**, with **95% test coverage (via pytest --cov)** and professionalâ€‘grade documentation.

The challenge required building a **complete referral analytics system** that models, analyzes, and optimizes referral networks. Specifically, it asked for:
- Directed Acyclic Graph (DAG) storage of oneâ€‘toâ€‘one referrals with constraints
- Multiâ€‘level reach analysis using graph traversal algorithms
- Influencer identification using greedy set cover and shortestâ€‘path flow centrality
- Network growth simulation with capacity limits and probabilistic modeling
- Incentive bonus optimization using a callable adoptionâ€‘probability model

---

## 1ï¸âƒ£ Part 1 â€“ Referral Graph Core Logic

**Spec:**  
Maintain a **DAG** of referral relationships enforcing:
- âœ” **Enforces** No selfâ€‘referrals
- âœ” **Enforces** One unique referrer per candidate
- âœ” **Enforces** No cycles allowed

**Implementation:**  
- **Class:** `ReferralNetwork` (`source/referral_network.py`)
- **Data Structures:**
  - `referrals`: `{candidate -> referrer}`
  - `reverse_referrals`: `{referrer -> set(candidates)}`
  - `users`: `set(all users)`
- **Cycle Detection:** `_would_create_cycle` (DFS) prevents adding edges that make a cycle.
- **Core Methods:**
  - `add_referral(referrer, candidate)`
  - `get_direct_referrals(user)`

**Test Coverage:**  
`test_add_referral`, `test_self_referral_prevention`, `test_cycle_prevention_simple`, `test_cycle_prevention_complex`, plus constraint & validation cases.

---

## 2ï¸âƒ£ Part 2 â€“ Full Network Reach

**Spec:**  
- âœ” Compute total (direct + indirect) reach for a user using BFS.
- âœ” Output Topâ€‘K referrers ranked by reach.

**Implementation:**  
- `get_total_referral_count(user)` â€” BFS to count all reachable nodes.
- `get_top_referrers(k)`

**Test Coverage:**  
`test_get_total_referral_count_simple`, `test_get_total_referral_count_complex`, `test_get_top_referrers`, plus edge cases for empty and small networks.

---

## 3ï¸âƒ£ Part 3 â€“ Identify Influencers

### 3a. Unique Reach Expansion â€“ Greedy Set Cover

**Spec:**  
- âœ” Iteratively select the user providing **maximum NEW** downstream coverage until all users are covered.

**Implementation:**  
- `get_unique_reach_expansion()`:
  1. Compute reachable sets for each user
  2. Maintain `remaining_uncovered`
  3. Pick user with max marginal gain each round
  4. Remove covered users & repeat

**Test Coverage:**  
- Overlap scenarios: `test_get_unique_reach_expansion_greedy_behavior`
- Break conditions: `test_get_unique_reach_expansion_break_conditions`
- Edge cases: isolated or noâ€‘reach users

---

### 3b. Flow Centrality â€“ Shortestâ€‘Path Criterion

**Spec:**  
- âœ” Count how many shortest paths between `(s, t)` pass through `v`, using:  
- âœ” `dist(s,v) + dist(v,t) == dist(s,t)`, via **allâ€‘pairs BFS**.

**Implementation:**  
- `_compute_shortest_paths(start)` â†’ BFS distances
- `_is_on_shortest_path(s, t, v, dist_s, dist_v)` â†’ spec condition check
- `get_flow_centrality()` â†’ loops all `(s, t)` pairs excluding endpoints

**Test Coverage:**  
`test_get_flow_centrality_simple`, `test_get_flow_centrality_complex`, plus cases w/ no paths, insufficient users.

---

## 4ï¸âƒ£ Part 4 â€“ Network Growth Simulation

**Spec:**  
- âœ” Start: `100` active referrers
- âœ” Each max `10` referrals before becoming inactive
- âœ” `p`: daily referral probability
- âœ” Determine:
  - Referral totals over time
  - Min days to hit target

**Implementation:**  
- **Class:** `NetworkSimulator` (`source/simulation.py`)
- Methods:
  - `simulate(p, days)` â€” stochastic (random)
  - `simulate_expected(p, days)` â€” deterministic expectation
  - `days_to_target(p, target_total)` â€” binary search for required days

**Test Coverage:**  
Probability range checks, capacity limits, reproducibility, edge cases.

---

## 5ï¸âƒ£ Part 5 â€“ Referral Bonus Optimization

**Spec:**  
- âœ” Given `adoption_prob(bonus)` (monotonic callable), find min bonus ($10 increments) to hit hiring target in given days.

**Implementation:**  
- **Class:** `ReferralBonusOptimizer`
- `min_bonus_for_target(days, target, adoption_prob, eps)` â€” binary search  
- `analyze_bonus_effectiveness()` â€” total cost & cost/hire metrics

**Test Coverage:**  
Various callable forms (linear, exponential, step), impossible targets, min increments, eps handling.

---

## ğŸ“‚ Deliverables

```
mercor-challenge/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ source/
â”‚   â”œâ”€â”€ referral_network.py
â”‚   â””â”€â”€ simulation.py
â””â”€â”€ tests/
    â”œâ”€â”€ test_referral_network.py
    â””â”€â”€ test_simulation.py
```

- **README.md**: Project overview, setup, spec compliance, and testing instructions
- **requirements.txt**: Python dependency listing
- **source/referral_network.py**: Referral graph, analytics, influencer logic
- **source/simulation.py**: Network growth simulation & bonus optimization
- **tests/test_referral_network.py**: Unit/integration tests (Parts 1â€“3)
- **tests/test_simulation.py**: Unit/integration tests (Parts 4â€“5)

README includes setup, design choices, complexity analysis, and AI tool usage disclosure.

---

## â–¶ How to Run

**Install:**
```
pip install -r requirements.txt
```

**Run tests:**
```
pytest
```

**Run with coverage:**
```
pytest --cov=source --cov-report=term-missing
```

---

## ğŸ— Design Choices

- **OOP modularity:** Separate graph logic, simulation, and optimization
- **BFS/DFS:** Simplicity & clarity for reach & cycle detection
- **Greedy set cover:** Guarantees optimal marginal gain for unique reach
- **Allâ€‘Pairs BFS:** Accurate shortestâ€‘path centrality
- **Binary Search:** Efficient bonus/minâ€‘days calculations

---

## â± Complexity & Space

| Operation                          | Time Complexity      | Space Complexity |
|------------------------------------|----------------------|------------------|
| Add Referral                       | O(1) / O(V) worst    | O(V+E)           |
| Total Reach BFS                    | O(V+E)               | O(V+E)           |
| Topâ€‘K Referrers                     | O(V log V)           | O(V)             |
| Unique Reach Expansion              | O(VÂ²)                | O(VÂ²)            |
| Flow Centrality (Allâ€‘Pairs BFS)     | O(VÂ³ Ã— E)             | O(VÂ²)            |
| Simulate                            | O(days Ã— active)     | O(active)        |
| Days to Target                      | O(log days Ã— active) | O(active)        |
| Bonus Optimization                  | O(log B Ã— days Ã— active) | O(active)   |

---

## ğŸ§ª Testing Strategy

**82 tests**, **95% coverage (via pytest --cov)**:
- **Part 1:** Constraints, DAG validation
- **Part 2:** BFS reach & ranking
- **Part 3:** Greedy set cover, shortestâ€‘path centrality
- **Part 4:** Capacity limits, daysâ€‘toâ€‘target
- **Part 5:** Callable interface, various prob. shapes, edge cases
- Performance & reproducibility: deterministic mode + seeds

**Coverage checked as of August 2025, using Python 3.11, pytest 7.x, and pytestâ€‘cov 4.x.**

---

## ğŸ“Š Business Use Cases

**Total Reach:** Measure general influence  
**Unique Reach Expansion:** Minimal influencer sets for campaigns  
**Flow Centrality:** Bottleneck discovery & network resilience  
**Growth Simulation:** Forecasting recruiter activity & hiring  
**Bonus Optimization:** Minâ€‘cost incentive planning

---

## ğŸ“ˆ Future Enhancements
- Graph visualization dashboards
- Temporal network analysis
- Predictive modeling
- REST API for integration

---

## ğŸ¤– AI Tool Usage Disclosure
Development was **humanâ€‘led and specâ€‘driven**.  
The main AI tools used during development were **Perplexity** and **Google Gemini**, which assisted with:
- Accelerating test creation
- Refining documentation
- Refactoring code for clarity

---
## â³ Approximate Time Spent
6 hours total, including design, implementation, testing, documentation, and refinements.

---

## âœ… Compliance Statement
This submission meets **100%** of the functional, interface, and performance requirements of the *Mercor Referral Network Challenge*, verified against the spec and validated by an automated 95%â€‘coverage test suite.

---

For any clarification or detailed code review, please see docstrings in source files or contact for additional information. All source code is thoroughly documented with comprehensive docstrings for easy review.
